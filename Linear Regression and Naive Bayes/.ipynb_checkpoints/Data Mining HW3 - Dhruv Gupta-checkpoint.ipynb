{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 \n",
    "a) Write and explain about the Linear Regression and it's equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans) \n",
    "Linear regression is used for prediction. Prediction is useful when an input value is readily available and the output variable is not. Eg. To predict the stock prices for next month using data from last year. \n",
    "\n",
    "Linear regression is a supervised learning approach that models the dependance of Y on the covariates $X_1, X_2, .., X_p$ as being linear: \n",
    "\n",
    "$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2+... + \\beta_pX_p + \\epsilon  \n",
    "\\\\ = \\beta_0 + \\sum_{j=1}^p \\beta_jX_j+\\epsilon\n",
    "$\n",
    "\n",
    "the true regression function $E(Y|X=x)$ \\\\  \n",
    "This is the expected value of Y at X = x, might not be linear.\n",
    "Linear regression aims to estimate the true regression function\n",
    "\n",
    "The Linear regression is calculated by fitting a line equation to a given data set with minium variance. This process is represented by the following equations: \n",
    "\n",
    "$\n",
    "\\hat{y_i} = b_0 + b_1x_i\n",
    "$ \n",
    "\n",
    "Where \n",
    "$\n",
    "b_1 = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar(y) }{ \\sum(x_i-\\bar{x})^2} \\\\\n",
    "b_0 = \\bar{y}-b_1\\bar{x}  \\\\\n",
    "$\n",
    "\n",
    "$ \\bar{x} = $ mean of the independant variable\n",
    "\n",
    "$ \\bar{y} =$ mean of the dependant variable \n",
    "\n",
    "$x_i =$ value of independant variable \n",
    "\n",
    "$y_i =$ value of dependant variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) \n",
    "Explain in detail about the loss function of linear regression, $R^2$, Adjusted $R^2$ used\n",
    "in the Linear Regression and what is the need for Adjusted $R^2$? [12 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans) \n",
    "\n",
    "$\n",
    "\\hat{y_i} = b_0 + b_1x_i\n",
    "$ \n",
    "\n",
    "Linear regression estimates the parameters $b_1$ by finding the parameter values that minimize the residual sum of squares (RSS)\n",
    "\n",
    "$\n",
    "RSS = \\sum_{(i=1)}^n (y_i-\\hat{y_i})^2 \\\\\n",
    "RSS = \\sum_{i=1}^n (y_i-[\\hat{b_0} + \\hat{b_1}x_{i1} + ... + \\hat{b_p}x_{ip}))])^2\n",
    "$\n",
    "\n",
    "The quantity $e_i = y_i-\\hat(y_i)$ is called a residual\n",
    "\n",
    "R-squared explains to what extent the variance of one variable explains the variance of the second variable. So, if the R2 of a model is 0.50, then approximately half of the observed variation can be explained by the model's inputs.\n",
    "\n",
    "R-Squared only works as intended in a simple linear regression model with one explanatory variable. With a multiple regression made up of several independent variables, the R-Squared must be adjusted. The adjusted R-squared compares the descriptive power of regression models that include diverse numbers of predictors. Every predictor added to a model increases R-squared and never decreases it. Thus, a model with more terms may seem to have a better fit just for the fact that it has more terms, while the adjusted R-squared compensates for the addition of variables and only increases if the new term enhances the model above what would be obtained by probability and decreases when a predictor enhances the model less than what is predicted by chance. In an overfitting condition, an incorrectly high value of R-squared, which leads to a decreased ability to predict, is obtained. This is not the case with the adjusted R-squared.\n",
    "\n",
    "While standard R-squared can be used to compare the goodness of two or model different models, adjusted R-squared is not a good metric for comparing nonlinear models or multiple linear regressions.\n",
    "\n",
    "Limitations Of R-Squared\n",
    "R-squared will give you an estimate of the relationship between movements of a dependent variable based on an independent variable's movements. It doesn't tell you whether your chosen model is good or bad, nor will it tell you whether the data and predictions are biased. A high or low R-square isn't necessarily good or bad, as it doesn't convey the reliability of the model, nor whether you've chosen the right regression. You can get a low R-squared for a good model, or a high R-square for a poorly fitted model, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Plot X vs Y in Scatter plot from data in Table 1 and comment on the relation of X vs Y using Covariance,Corelation. Please comment on Covariance and corelation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [6,3,6,9,3,9,6,3,9,6,3,9]\n",
    "Y = [526,421,581,630,412,560,434,443,590,570,346,672]\n",
    "\n",
    "plt.scatter(X,Y)\n",
    "plt.title('Scatter plot of Table 1')\n",
    "plt.xlabel('x - Weeks')\n",
    "plt.ylabel('y - Sales')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6   3   6   9   3   9   6   3   9   6   3   9]\n",
      " [526 421 581 630 412 560 434 443 590 570 346 672]]\n",
      "\n",
      "covariance: \n",
      "[[6.54545455e+00 2.26363636e+02]\n",
      " [2.26363636e+02 1.02522652e+04]]\n",
      "\n",
      "correlation: \n",
      "[[1.         0.87382978]\n",
      " [0.87382978 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.stack((X, Y), axis=0)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "covariance = np.cov(x)\n",
    "correlation = np.corrcoef(X, Y)\n",
    "\n",
    "print('covariance: ')\n",
    "print(covariance)\n",
    "print()\n",
    "print('correlation: ')\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation tells us that 87% of the variance in y can be explained by x. This means that the 2 variables are strongly corelated. \n",
    "\n",
    "Covariance does not provide the strength of the relation, rather only if the 2 variable have a positive or negative linear relation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Perform Linear regression on the following data using Python? and print b0, b1\n",
    "values in equation y= b0+ b1*x. Please write down what is your understanding from\n",
    "those values. [10 Pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 307.91666666666663\n",
      "slope: [34.58333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "in1 = np.array(X).reshape((-1,1))\n",
    "in2 = np.array(Y)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(in1, in2)\n",
    "\n",
    "# With .fit(), you calculate the optimal values of the weights 𝑏₀ and 𝑏₁, using the existing \n",
    "# input and output (x and y) as the arguments. In other words, .fit() fits the model. \n",
    "# It returns self, which is the variable model itself. \n",
    "\n",
    "\n",
    "print('intercept:', model.intercept_) # Represents b0\n",
    "print('slope:', model.coef_) # Represents b1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluated values of b0 and b1 are parameters required for building a linear model which can be used to predict new values of y. b0 is the y intercept of the line and b1 is slope of this line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) What are different evaluation metrics available for predicting the performance of the\n",
    "Linear Regression? Evaluate all those methods on the given dataset in Table 1 and\n",
    "also please print out the accuracy, R2, Adjusted R2 [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following metrics can be used to evaluate a regression model:\n",
    "- R-squared\n",
    "- Average Error\n",
    "- Mean Square Error (MSE)\n",
    "- Average absolute error\n",
    "- Median absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination(R^2): 0.7635784848728921\n",
      "Adjusted R^2:  0.5413573128168596\n",
      "Mean Squared Error:  2221.868055555555\n",
      "Mean Absolute Error:  39.23611111111112\n",
      "RMSE:  47.136695424642944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "r_sq = model.score(in1, in2)\n",
    "print('coefficient of determination(R^2):', r_sq)\n",
    "# When you’re applying .score(), the arguments are also the predictor x and regressor y, and the return value is 𝑅².\n",
    "\n",
    "n = len(X)\n",
    "p = 1\n",
    "adj_R2 = 1-(1-r_sq ** 2)*((n-1)/(n-p-1))\n",
    "\n",
    "print(\"Adjusted R^2: \", adj_R2)\n",
    "\n",
    "y_pred = model.predict(in1)\n",
    "MSE = mean_squared_error(in2, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error: \",MSE)\n",
    "print(\"Mean Absolute Error: \",mean_absolute_error(in2, y_pred))\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(in2, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Print ANOVA (Analysis of Variance) table and Parameter Estimates for the given data and explain your understanding.[See hints and explanation for what I am looking for] [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans) \n",
    "The analysis of variance (ANOVA) can be thought of as an extension to the t-test. The independent t-test is used to compare the means of a condition between 2 groups. ANOVA is used when one wants to compare the means of a condition between 2+ groups. ANOVA is an omnibus test, meaning it tests the data as a whole. Another way to say that is this, ANOVA tests if there is a difference in the mean somewhere in the model (testing if there was an overall effect), but it does not tell one where the difference is if the there is one. To find out where the difference is between the groups, one has to conduct post-hoc tests.\n",
    "\n",
    "There are 3 assumptions that need to be met for the results of an ANOVA test to be considered accurate and trust worthy. It’s important to note the the assumptions apply to the residuals and not the variables themselves. The ANOVA assumptions are the same as for linear regression and are:\n",
    "\n",
    "- Normality\n",
    "    - Caveat to this is, if group sizes are equal, the F-statistic is robust to violations of normality\n",
    "- Homogeneity of variance\n",
    "    - Same caveat as above, if group sizes are equal, the F-statistic is robust to this violation\n",
    "- Independent observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Weeks  Sales\n",
      "0       6    526\n",
      "1       3    421\n",
      "2       6    581\n",
      "3       9    630\n",
      "4       3    412\n",
      "5       9    560\n",
      "6       6    434\n",
      "7       3    443\n",
      "8       9    590\n",
      "9       6    570\n",
      "10      3    346\n",
      "11      9    672\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import researchpy as rp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# print(x[1][1])\n",
    "data = dict()\n",
    "data[0] = list()\n",
    "data[1] = list()\n",
    "data[2] = list()\n",
    "\n",
    "i=0\n",
    "for ea in x[0]:\n",
    "    if ea == 3:\n",
    "        data[0].append(x[1][i])\n",
    "    elif ea == 6:\n",
    "        data[1].append(x[1][i])\n",
    "    else:\n",
    "        data[2].append(x[1][i])\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Weeks': x[0, :], 'Sales': x[1, :]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>405.50</td>\n",
       "      <td>41.749251</td>\n",
       "      <td>20.874626</td>\n",
       "      <td>358.256274</td>\n",
       "      <td>452.743726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>527.75</td>\n",
       "      <td>66.864914</td>\n",
       "      <td>33.432457</td>\n",
       "      <td>452.085227</td>\n",
       "      <td>603.414773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>613.00</td>\n",
       "      <td>48.675798</td>\n",
       "      <td>24.337899</td>\n",
       "      <td>557.918149</td>\n",
       "      <td>668.081851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       N    Mean         SD         SE   95% Conf.    Interval\n",
       "Weeks                                                         \n",
       "3      4  405.50  41.749251  20.874626  358.256274  452.743726\n",
       "6      4  527.75  66.864914  33.432457  452.085227  603.414773\n",
       "9      4  613.00  48.675798  24.337899  557.918149  668.081851"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gettin summary statistics\n",
    "rp.summary_cont(df['Sales'].groupby(df['Weeks']))\n",
    "# rp.summary_cont(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 13 Oct 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:40:39</td>     <th>  Log-Likelihood:    </th> <td> -63.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   132.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     9</td>      <th>  BIC:               </th> <td>   133.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>  405.5000</td> <td>   26.745</td> <td>   15.162</td> <td> 0.000</td> <td>  345.000</td> <td>  466.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Weeks)[T.6]</th> <td>  122.2500</td> <td>   37.823</td> <td>    3.232</td> <td> 0.010</td> <td>   36.690</td> <td>  207.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Weeks)[T.9]</th> <td>  207.5000</td> <td>   37.823</td> <td>    5.486</td> <td> 0.000</td> <td>  121.940</td> <td>  293.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.256</td> <th>  Durbin-Watson:     </th> <td>   2.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.534</td> <th>  Jarque-Bera (JB):  </th> <td>   0.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.589</td> <th>  Prob(JB):          </th> <td>   0.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.234</td> <th>  Cond. No.          </th> <td>    3.73</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.772\n",
       "Model:                            OLS   Adj. R-squared:                  0.721\n",
       "Method:                 Least Squares   F-statistic:                     15.21\n",
       "Date:                Sun, 13 Oct 2019   Prob (F-statistic):            0.00130\n",
       "Time:                        19:40:39   Log-Likelihood:                -63.055\n",
       "No. Observations:                  12   AIC:                             132.1\n",
       "Df Residuals:                       9   BIC:                             133.6\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept       405.5000     26.745     15.162      0.000     345.000     466.000\n",
       "C(Weeks)[T.6]   122.2500     37.823      3.232      0.010      36.690     207.810\n",
       "C(Weeks)[T.9]   207.5000     37.823      5.486      0.000     121.940     293.060\n",
       "==============================================================================\n",
       "Omnibus:                        1.256   Durbin-Watson:                   2.248\n",
       "Prob(Omnibus):                  0.534   Jarque-Bera (JB):                0.987\n",
       "Skew:                          -0.589   Prob(JB):                        0.611\n",
       "Kurtosis:                       2.234   Cond. No.                         3.73\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ols('Sales ~ C(Weeks)', data=df).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model is significiant, F(2,9)= 15.21, p = 0.00130. This tells us that there is a significant difference in the group means. The coefficients (coef in the table), are the difference in mean between the control group and the respective group listed. \n",
    "\n",
    "The intercept is the mean for weeks = 3, weeks = 9 group’s coefficient = 613 – 405.5 = 207.5, and weeks = 6 coefficient = 527.75 – 405.5 = 122.2500. Looking at the p-values now (P>|t| in the table), we can see the difference between the groups 3 and 9 is significant, p = 0.000, but the difference between 3 and 6 is not, p = 0.01. There is no comparison between the Week 6 and Week 9. I wanted to show you this to see where these numbers come from. Coming from the ANOVA framework, the information we are really after in this table it the F-statistic and it’s corresponding p-value. This tells us if we explained a significant amount of the overall variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C(Weeks)</td>\n",
       "      <td>87025.166667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.208429</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Residual</td>\n",
       "      <td>25749.750000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum_sq   df          F    PR(>F)\n",
       "C(Weeks)  87025.166667  2.0  15.208429  0.001299\n",
       "Residual  25749.750000  9.0        NaN       NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aov_table = sm.stats.anova_lm(results, typ=2)\n",
    "aov_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) What is Conditional probability, Marginal probability and Joint probability? Write their mathematical formulas and give one example each. [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional probability of an event B is the probability that the event will occur given the knowledge that an event A has already occurred. This probability is written P(B|A), notation for the probability of B given A. \n",
    "\n",
    "$ \n",
    "P(B|A) = \\frac{P(A and B)}{P(A)}\n",
    "$\n",
    "\n",
    "Eg. \n",
    "In a card game, suppose a player needs to draw two cards of the same suit in order to win. Of the 52 cards, there are 13 cards in each suit. Suppose first the player draws a heart. Now the player wishes to draw a second heart. Since one heart has already been chosen, there are now 12 hearts remaining in a deck of 51 cards. So the conditional probability P(Draw second heart|First card a heart) = 12/51.\n",
    "\n",
    "Marginal probability: Probability of a single event irrespective of any other event. For instance, the probability of a coin flip giving a head is considered a marginal probability because we aren’t considering any other events.\n",
    "$P(A) = P(A)$\n",
    "\n",
    "\n",
    "Joint probability: The probability of two events occurring simultaneously. The probability of the intersection of A and B may be written p(A ∩ B). Eg. the probability that a card is a four and red =p(four and red) = 2/52=1/26.  (There are two red fours in a deck of 52, the 4 of hearts and the 4 of diamonds).\n",
    "\n",
    "$P(A,B) = P(A).P(B)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Explain what is Baye's rule with the formula and what is prior, posterior, likelihood\n",
    "and marginal probability in the Baye's rule. [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem is a formula that describes how to update the probabilities of hypotheses when given evidence. It follows simply from the axioms of conditional probability, but can be used to powerfully reason about a wide range of problems involving belief updates.\n",
    "\n",
    "Given a hypothesis H and evidence E, Bayes' theorem states that the relationship between the probability of the hypothesis before getting the evidence P(H) and the probability of the hypothesis after getting the evidence $P(H \\mid E)$ is\n",
    "\n",
    "$P(H|E) = \\frac{P(E|H)}{P(E)}P(H)$\n",
    "\n",
    "$P(H)$ is the prior probability or marginal probability of H. It is ”prior” in the sense that it does not take into account any information about E.\n",
    "\n",
    "$P(E|H)$ is the conditional probability of E, given H. It is also called the posterior probability because it is derived from or depends upon the specified value of H\n",
    "\n",
    "$P(E|H)$ is the conditional probability of E given H.\n",
    "\n",
    "$P(E)$ is the prior or marginal probability of E, and acts as a normalizing constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) What is Naive Bayes algorithm and how is related or derived or inspired from Bayes\n",
    "rule? [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Perfom Naive Bayes algorithm on the below dataset in python in which you can\n",
    "classify wheather a Red Domestic SUV is stolen or not as shown in 2.2. [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
