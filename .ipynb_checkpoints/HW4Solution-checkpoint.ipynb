{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Work 4 : Apeksha Hada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is cross-validation? Explain everything in detail about how the cross validation can be performed on given dataset[10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross-validation, it’s a model validation techniques for assessing how the results of a statistical analysis (model) will generalize to an independent data set. It is mainly used in settings where the goal is prediction, and one wants to estimate how accurately a predictive model will perform in practice.\n",
    "The goal of cross-validation is to define a data set to test the model in the training phase (i.e. validation data set) in order to limit problems like overfitting,underfitting and get an insight on how the model will generalize to an independent data set.\n",
    "\n",
    "This method follows the below steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"CrossValidation.png\", width=500,height=500>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"CrossValidation.png\", width=500,height=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Split the entire data randomly into k folds (value of k shouldn’t be too small or too high, ideally we choose 5 to 10 depending on the data size). The higher value of K leads to less biased model (but large variance might lead to overfit), where as the lower value of K is similar to the train-test split approach we saw before.\n",
    "\n",
    "2. Then fit the model using the K — 1 (K minus 1) folds and validate the model using the remaining Kth fold. Note down the scores/errors.\n",
    "\n",
    "3. Repeat this process until every K-fold serve as the test set. Then take the average of your recorded scores. That will be the performance metric for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What are advantages and disadvantages of Cross validation? [5 Pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:\n",
    "    Holdout method: The advantage of this method is that it is usually preferable to the residual method and takes no longer to compute.\n",
    "    K-fold cross validation: The advantage of this method is that it matters less how the data gets divided. Every data point gets to be in a test set exactly once, and gets to be in a training set k-1 times.\n",
    "                             The variance of the resulting estimate is reduced as k is increased.\n",
    "        \n",
    "                            The disadvantage of this method is that the training algorithm has to be rerun from scratch k times, which means it takes k times as much computation to make an evaluation.\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What is Generalized Additive Models?[Please refer to our course textbook Elements of Statistical Learning Textbook for this] [5 Pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:\n",
    "    Many data in the environmental sciences do not fit simple linear models and are best described by “wiggly models”\n",
    "    , also known as Generalised Additive Models (GAMs).\n",
    "    \n",
    "Try fitting a normal linear model to this plot:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Plot.png\", width=200,height=200>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"Plot.png\", width=200,height=200>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The GAM framework is based on an appealing and simple mental model:\n",
    "\n",
    "1. Relationships between the individual predictors and the dependent variable follow smooth patterns that can be linear or nonlinear.\n",
    "\n",
    "2. We can estimate these smooth relationships simultaneously and then predict g(E(Y))) by simply adding them up\n",
    "\n",
    "\n",
    "In the regression setting, a generalized additive model has the form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Gene.png\", width=500,height=500>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"Gene.png\", width=500,height=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The fj ’s are unspecified smooth (“nonparametric”) functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How does Decision Tree Based Method’s differ from the rest of the classification meth- ods? [5 Pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer: \n",
    "\n",
    "In Decision Tree, at each point, you consider a set of questions that can partition your data set.\n",
    "One of the reasons they are so powerful is because they can be easily visualised so that a human can understand whats going on.\n",
    "\n",
    "Disadvantages of decision trees: \n",
    "    They are unstable, meaning that a small change in the data can lead to a large change in the structure of the optimal decision tree.\n",
    "    They are often relatively inaccurate. Many other predictors perform better with similar data.\n",
    "    \n",
    "    For data including categorical variables with different number of levels, information gain in decision trees \n",
    "    is biased in favor of those attributes with more levels.\n",
    "\n",
    "    Calculations can get very complex, particularly if many values are uncertain and/or if many outcomes are linked.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What are different classification techniques available and How does a Decision Tress work? [Please write in atleast 5 sentences] [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:\n",
    "Classification techniques:\n",
    "    \n",
    "    1. Logistic Regression\n",
    "        It is a machine learning algorithm for classification. In this algorithm, the probabilities describing the possible outcomes of a single trial are modelled using a logistic function.\n",
    "    \n",
    "    2. Naïve Bayes\n",
    "        It is based on Bayes’ theorem with the assumption of independence between every pair of features. Naive Bayes classifiers work well in many real-world situations such as document classification and spam filtering.\n",
    "    \n",
    "    3. K-Nearest Neighbours\n",
    "        Neighbours based classification is a type of lazy learning as it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the k nearest neighbours of each point.\n",
    "     \n",
    "    4. Support Vector Machine\n",
    "        It is a representation of the training data as points in space separated into categories by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.\n",
    "    \n",
    "    5. Decision Trees \n",
    "        At each point, you consider a set of questions that can partition your data set.\n",
    "        You choose the question that provides the best split and again find the best questions for the partitions.\n",
    "        \n",
    "        How it works:\n",
    "            Decision tree builds classification or regression models in the form of a tree structure. \n",
    "            It breaks down a data set into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. \n",
    "            The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches. \n",
    "            Leaf node represents a classification or decision. The topmost decision node in a tree which corresponds to the best predictor called root node. \n",
    "            Decision trees can handle both categorical and numerical data.\n",
    "            \n",
    "            Splitting: The process of partitioning the data set into subsets. Splits are formed on a particular variable.\n",
    "            \n",
    "            Step 1: Calculate entropy of the target.\n",
    "            Step 2: The dataset is then split on the different attributes. The entropy for each branch is calculated. Then it is added proportionally, to get total entropy for the split. The resulting entropy is subtracted from the entropy before the split. The result is the Information Gain, or decrease in entropy.\n",
    "            Step 3: Choose attribute with the largest information gain as the decision node, divide the dataset by its branches and repeat the same process on every branch.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. What are some of the advantages and disadvantages of decision trees? [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-74121a8f43d2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-74121a8f43d2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Advantages:\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Advantages:\n",
    "\n",
    "1. Are simple to understand and interpret. People are able to understand decision tree models after a brief explanation.\n",
    "2. Have value even with little hard data. Important insights can be generated based on experts describing a situation (its alternatives, probabilities, and costs) and their preferences for outcomes.\n",
    "3. Help determine worst, best and expected values for different scenarios.\n",
    "4. Use a white box model. If a given result is provided by a model.\n",
    "5. Can be combined with other decision techniques.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "1. They are unstable, meaning that a small change in the data can lead to a large change in the structure of the optimal decision tree.\n",
    "2. They are often relatively inaccurate. Many other predictors perform better with similar data. This can be remedied by replacing a single decision tree with a random forest of decision trees, but a random forest is not as easy to interpret as a single decision tree.\n",
    "3. For data including categorical variables with different number of levels, information gain in decision trees is biased in favor of those attributes with more levels.[7]\n",
    "4. Calculations can get very complex, particularly if many values are uncertain and/or if many outcomes are linked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. What are different subset selection based methods and explain the difference between subset selection based method’s vs cross validation [Explain with example] [10 Pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer:\n",
    "    Subset selection evaluates a subset of features as a group for suitability. \n",
    "    Subset selection algorithms can be broken up into wrappers, filters, and embedded methods.\n",
    "    Wrappers use a search algorithm to search through the space of possible features and evaluate each subset by running a model on the subset.\n",
    "    Filters are similar to wrappers in the search approach, but instead of evaluating against a model, a simpler filter is evaluated.\n",
    "    Embedded techniques are embedded in, and specific to, a model.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Please Perform Logistic Classification on the Give dataset (insurance-data.csv) below.[10 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  bought_insurance\n",
       "0   22                 0\n",
       "1   25                 0\n",
       "2   47                 1\n",
       "3   52                 0\n",
       "4   46                 1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('insurance_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13    29\n",
      "19    18\n",
      "20    21\n",
      "16    25\n",
      "1     25\n",
      "10    18\n",
      "26    23\n",
      "25    54\n",
      "8     62\n",
      "6     55\n",
      "4     46\n",
      "18    19\n",
      "9     61\n",
      "7     60\n",
      "22    40\n",
      "3     52\n",
      "0     22\n",
      "21    26\n",
      "15    55\n",
      "12    27\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x = df['age']\n",
    "y = df['bought_insurance']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split( \n",
    "        x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(xtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "#ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest = xtest.values.reshape(-1, 1)\n",
    "\n",
    "classifier.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(xtest)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[1 0]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(ytest, y_pred) \n",
    "  \n",
    "print (\"Confusion Matrix : \\n\", cm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap \n",
    "X_set, y_set = xtest, ytest \n",
    "\n",
    "for i, j in enumerate(np.unique(y_set)): \n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 0], \n",
    "                c = ListedColormap(('red', 'green'))(i), label = j) \n",
    "      \n",
    "plt.title('Classifier (Test set)') \n",
    "plt.xlabel('Age') \n",
    "plt.ylabel('Bought Insurance?') \n",
    "plt.legend() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Please Perform Decision Tree Classification on the Give dataset(data.csv) below.[40 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.833</td>\n",
       "      <td>204600</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>-8.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>150.062</td>\n",
       "      <td>4</td>\n",
       "      <td>0.286</td>\n",
       "      <td>Mask Off</td>\n",
       "      <td>Future</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.743</td>\n",
       "      <td>326933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>-10.401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>160.083</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588</td>\n",
       "      <td>Redbone</td>\n",
       "      <td>Childish Gambino</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.838</td>\n",
       "      <td>185707</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>-7.148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>75.044</td>\n",
       "      <td>4</td>\n",
       "      <td>0.173</td>\n",
       "      <td>Xanny Family</td>\n",
       "      <td>Future</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.494</td>\n",
       "      <td>199413</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>-15.236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>86.468</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230</td>\n",
       "      <td>Master Of None</td>\n",
       "      <td>Beach House</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.678</td>\n",
       "      <td>392893</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>-11.648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>174.004</td>\n",
       "      <td>4</td>\n",
       "      <td>0.904</td>\n",
       "      <td>Parallel Lines</td>\n",
       "      <td>Junior Boys</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0        0.0102         0.833       204600   0.434          0.021900    2   \n",
       "1        0.1990         0.743       326933   0.359          0.006110    1   \n",
       "2        0.0344         0.838       185707   0.412          0.000234    2   \n",
       "3        0.6040         0.494       199413   0.338          0.510000    5   \n",
       "4        0.1800         0.678       392893   0.561          0.512000    5   \n",
       "\n",
       "   liveness  loudness  mode  speechiness    tempo  time_signature  valence  \\\n",
       "0    0.1650    -8.795     1       0.4310  150.062               4    0.286   \n",
       "1    0.1370   -10.401     1       0.0794  160.083               4    0.588   \n",
       "2    0.1590    -7.148     1       0.2890   75.044               4    0.173   \n",
       "3    0.0922   -15.236     1       0.0261   86.468               4    0.230   \n",
       "4    0.4390   -11.648     0       0.0694  174.004               4    0.904   \n",
       "\n",
       "       song_title            artist  target  \n",
       "0        Mask Off            Future       1  \n",
       "1         Redbone  Childish Gambino       1  \n",
       "2    Xanny Family            Future       1  \n",
       "3  Master Of None       Beach House       1  \n",
       "4  Parallel Lines       Junior Boys       1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15 Points for Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['acousticness','danceability','duration_ms','energy','instrumentalness','key','liveness','loudness','mode','speechiness','tempo','time_signature','valence']\n",
    "X = df1[feature_cols]\n",
    "y = df1.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-e2816f0728af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n\u001b[1;32m     10\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path, f, prog)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1810\u001b[0;31m                 \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m             )\n\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, path, prog, format)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m                 \u001b[0mfobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[0;32m-> 1960\u001b[0;31m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('diabetes.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
